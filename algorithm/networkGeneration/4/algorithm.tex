\documentclass[12pt,a4paper]{report}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{mathrsfs}
 \usepackage{amsmath}


\title{Social Networking Study on DeviantArt Artificial Network Algorithm}

\date{\emph{04.05.2011} \\ \emph{Version 4.0} }

\author{CmpE 492 Project\\
	By: Ferhat Elmas \\
	Student Id: 2006101102\\
	Advisor: Haluk Bing\"{o}l
}

\begin{document}
\pagenumbering{roman}

\maketitle

\begin{table}[htdp]
\begin{center}
\textup{\Huge Version History}
\begin{tabular}{|c|c|p{10cm}|}
\hline
\textbf{Version} & \textbf{Date} & \textbf{Explanation} \\
\hline
1.0 & 30.03.2011 & Algorithm Design and Specification \\
\hline
2.0& 22.04.2011 & Some errors (keyword, logic, notation) are fixed, the details of the distributions of the deviant and deviation generation and a table of some basic properties of distributions are added, algorithm is improved and details are added\\
\hline
3.0& 27.04.2011& Parameter Analysis is added\\
\hline
4.0& 04.05.2011& Notation is improved, appendix is added, design of the chapters is changed\\
\hline
&&\\
\hline
\end{tabular}
\end{center}
\end{table}

%\clearpage

\begin{abstract}
	
	\par Influential users are very important in the network in terms of their ability to change the distribution of the interconnections in the network. In our case, the favorite relation of the DeviantART network is investigated. Favorite relation is a interconnection between users and resources. If a user likes a resource that he views, he adds it into his list and a favorite relation is constructed. Moreover, favorite relation is so effective to increase or decrease the value of a resource in the community. If a well known user adds a resource into his list, the value of the resource increases rapidly because a lot of users follow the well known user and imitate what the well known user does and other users also add this resource into their list, by the way this resource is entered a lot of favorite lists. In this paper, an algorithm to find the most influential user respect to favorite relation is expressed. 
	
	On the other hand, this algorithm is a result of some set of the assumptions. Therefore, an artificial network is created to test the power of the algorithm and the details of the generation and assumptions of the articial network are defined in the data generation phase.
\end{abstract}

\tableofcontents

\chapter{Introduction}
\pagenumbering{arabic}
	
	\par \hspace{0.6cm}Networks are all around us.  Your circle of friends; the route you take to work; cars on the road; tiny neurons firing inside your brain; ecological systems.  Understanding how elements within these networks interact has fascinated scientists for decades, with pivotal results such as 6-degrees of separation, Small World Networks, to name just a few, having application to easing road congestion, enhancing computer systems and understanding human social processes. 

	\par However, all such analysis are insufficient, yet there is a need of finding the central and/or influential nodes. This project is interested in closing the gap by presenting an algorithm to find the the important nodes. Therefore, DeviantART network is chosen because DeviantART is one of the biggest networks in the online world and there is a little research on this network. 

	\par Different algorithms can be easily developed by using different heuristics but we can't sure that the developed algorithm is the desired algorithm. Therefore, we need a network for testing. 

	\par In the first part generation of the test network is explained. Secondly, how can we find the most influential user in the network if we don't know anything about the internals of the network, this question is answered by presenting an alogrithm. Finally, test results are shown.

	Presented new method provides fascinating new directions for the development of new applications and new systems on online social networks and for a better understanding of social processes such as influence, trust and information spreading.

\chapter{Framework} 

	\hspace{0.6cm}There are mainly three components to represent the DeviantART network, namely, user, resource and favorite relation. In the following pages, user will be used instead of  deviant and resource will be used instead of deviation to decrease the confusion between deviant and deviation.

\section{User}

	\hspace{0.6cm}User object is defined to represent the users of the DeviantART.\\
	
	There are two properties, namely, \emph{id} and \emph{authority}. 

	$$User = \{(id, authority)\}$$
	
	\emph{id} is defined to select the users uniquely and varies from 1 to the number of the users. $\mathcal{U}$ is the set of the users and U is the size of the $\mathcal{U}$.

	$$|\mathcal{U}| = U $$

	$$\mathcal{U} = \{u_{1}, u_{2}, \dots, u_{U}\}$$ 

 	\emph{authority} is to specify the influentiality of the user. \emph{authority} is a function from $\mathcal{U}$ to $[0, 1)$ and returns a value from $[0, 1)$ for each user. The more influential user is, the closer to 1 \emph{authority} is.

	$$a : \mathcal{U} \to [0, 1)$$\\	

\section{Resource}

	\hspace{0.6cm}Resource object is defined to represent the artworks (pictures, drawings, clips, etc.) in the DeviantART.\\

	There are four properties, namely, \emph{id}, \emph{quality}, \emph{favorite list}, \emph{time list}. 

	$$Resource = \{(id, quality, favorite \text{ } list,  time \text{ } list)\}$$

	\emph{id} is defined to select the resources uniquely and varies from 1 to the number of the resources. $\mathcal{R}$ is the set of the resources and R is the size of the $\mathcal{R}$.

	$$|\mathcal{R}| = R $$

	$$\mathcal{R} = \{r_{1}, r_{2}, \dots, r_{R}\}$$ 
		

 \emph{quality} is to specify the art-criticique of the artwork. \emph{quality} is a function from $\mathcal{R}$ to $[0, 1)$ and returns a value from $[0, 1)$ for each resource. The higher quality resource is, the closer to 1 \emph{quality} is. 

	$$q : \mathcal{R} \to [0, 1)$$

\emph{favorite list} holds the ids of the users that added this resource to their favorite list.

	$$|fl(r_{i})| = k \Longrightarrow fl(r_{i}) =\{u_{1}, u_{2}, \dots, u_{k}\} \text{ where } r_{i} \in \mathcal{R} \text{ and } \{u_{1}, u_{2}, .., u_{k}\}  \subseteq \mathcal{U}$$ 

$D$ is the length of the days that have passed from the start of the DeviantART to present. 

	$$|\mathcal{D}| = D$$

	$$\mathcal{D} = \{d_{1}, d_{2}, \dots, d_{D}\}$$

Corollary to \emph{favorite list, time list} holds the days when these users added the resource. If a user added the resource before than others, his index will be smaller than others.

	$$|tl(r_{i})| = k \Longrightarrow tl(r_{i}) =\{d_{1}, d_{2}, .., d_{k}\} \text{ where } r_{i} \in \mathcal{R} \text{ and } d_{1} \le d_{2} \dots \le d_{k-1} \le d_{k} \le D\}$$ 

	$$|fl{r_{i}}| = |tl(r_{i})| \text{ must hold since they are respective lists of each other}$$

\clearpage

\section{Network} 

	\hspace{0.6cm}Network object is defined to represent favorite relation between users and resources in the DeviantART. Favorite relation maps users onto resources so each user chooses a subset of the resources set. \\

	$$Favorite = \{user, resource, day\}$$

	$$ \mathcal{F} = \{f(u_{i}, r_{j}, d_{k}) | u_{i} \in \mathcal{U}, r_{j} \in \mathcal{R}, d_{k} \in \mathcal{D}\}$$ \\

	We can imagine favorite relation ($\mathcal{F}$) as a bipartite matching where users and resources are nodes and adding into favorite list is the edge because there are two partitions composed of user ($\mathcal{U}$) and resource ($\mathcal{R}$) sets and there will be a link between partitions, not inside the partitions since users can add resources but can't follow the other users since we are just interested in favorite relation or resources can't be linked with other resources . Therefore, there will be an edge $f_{ijk}$ only if $u_{i}$ adds the $r_{j}$ into his list on the day $d_{k}$. \\

\chapter{Data Generation}

\section{Distributions of the Generation}

	\hspace{0.6cm}We definitely need a probability distribution to generate \emph{authority} values of the users and \emph{quality} values of the resources. Since a lot of users should have low \emph{authority} values and a lot of resources should have low \emph{quality} values, we need sharply decreasing probability distributions. Therefore, we chose two distributions: $2 - 2x$ and the family of $\frac{1}{x^n}$ where $n\ge 1$ and $x \in [0, 1)$. The first distribution is a real probability distribution but second one isn't since \\

	$$\int_{-\infty}^{\infty} \!  (2-2x)\, dx = 1$$ \\

	$$\int_{-\infty}^{\infty} \! \frac{1}{x^n}\, dx \not= 1$$ \\

	Therefore, there is a check while generating random stream with these distributions. If generated random number isn't in $[0, 1)$, repeat the procedure to get a number in the range. \\

	Inverse transform method is used to generate random variates from these distributions.

	\clearpage

	Random variate calculation of the $(2-2x)$ distribution:
	\begin{eqnarray*}
		 \int_{-\infty}^x \!  (2-2x)\, dx  = 2x -  x^2  & = & y \text{ where } y \in [0, 1) \text{ is a random number}\\
		x^2-2x+1 & = & 1 - y \\
		(x-1)^2 & = & 1 - y \\
		x - 1 & = & -\sqrt (1 - y) \\
		x & = & 1 - \sqrt(1-y)
	\end{eqnarray*}

	Since $y$ is randomly distributed, $1-y$ is also randomly distributed so we can use $y$ instead of $1-y$ and generator formula becomes 

	$$1-\sqrt y  \text{ where } y \text{ is a random number}$$ \\
		
	Random variate calculation of the family of the $(\frac{1}{x^n})$ distribution:
	\begin{eqnarray*}
		 \int_{-\infty}^x \!  (\frac{1}{x})\, dx  = \ln x & = & y \text{ where } y \in [0, 1) \text{ is a random number and } n = 1\\
		x & = & e^y \\
	\end{eqnarray*}

	However, by this formula we can calculate numbers which are outside of the range \\

	$$x \not\in [0, 1)$$ \\

	since the distribution isn't a probability distribution. We can check the generated values and take the values that are in the range but this is also so costly.\\

	Therefore, we thought about using minus logarithm of the random numbers to simulate the distribution and by dividing with $n$, whole family can be represented. \\

	\clearpage

	Generator formula becomes\\
	
	$$\frac{-\log y}{n} \text{ where } y \text{ is a random number and } n \ge 1 $$

	Moreover, we yet need to check each generated variate since this can also generate variates outside the range $[0, 1)$ but the probability of this is much smaller than the previous generator.

	While $n$ is increasing, the mean of the distribution decreases to zero which means that  a lot of users have small \emph{authority} values and have a minor effect on the network.

	$$\lim_{n \to +\infty} \frac{-\log y}{n} = 0 $$

\section{Generation of the Users}

	\hspace{0.6cm}\emph{id} property is incremented by one in each user generation. The value of the \emph{authority} property is generated by the chosen distribution function.

	$$u_{i} = \{(i, a_{i})| 1 \le i \le U, a_{i} \in [0,1) \} $$  

\section{Generation of the Resources}

	\hspace{0.6cm}\emph{id} property is incremented by one in each resource generation. The value of the \emph{quality} property is generated by the chosen distribution function.

	$$r_{i} = \{(i, q_{i})| 1 \le i \le R, q_{i} \in [0,1) \} $$  

\section{Matching of Deviants and Deviations}	
	
	\hspace{0.6cm}We have users and resources

	\begin{eqnarray*}
	\mathcal{U} = \{u_{i}|1 \le i \le U\}\\
	\mathcal{R} = \{r_{i}|1 \le i \le R\}
	\end{eqnarray*}

	By matching these two partitions we get favorite relation. 

	$$\mathcal{F} = \{f_{ijk} : (u_{i}, r_{j}, d_{k})| u_{i} \in \mathcal{U}, r_{j} \in \mathcal{R}, d_{k} \in \mathcal {D}\} $$

\clearpage

	\large{Matching algorithm:} 
	
	\begin{equation}
	 \hspace{-6cm}\text{For } d  =  1  \text{ to } D  
	\end{equation}

	\begin{equation}
   	\hspace{-4cm}t_{max}  \leftarrow  \mathcal{N}(\mu, \sigma^2) 
	\end{equation}	

	\begin{equation}	
	\hspace{-4cm}\text{For } t=1 \text{ to } t_{max} 		
	\end{equation}
	
	\begin{eqnarray}	
	&\hspace{-2.2cm}u_{i} \leftarrow \text{Uniform}[1, U] \nonumber \\
	&\hspace{-2.2cm}r_{j} \leftarrow \text{Uniform}[1, R]  		
	\end{eqnarray}	

	\begin{equation}
	\hspace{1cm}\text{if } f(u_{i}, r_{j}, d_{k}) \not \in \mathcal{F} \text{ where }\exists d_{k} \in \mathcal{D}
	\end{equation}

	\begin{eqnarray}	
	\hspace{2.8cm}fl(r_{j}) & = &fl(r_{j}) \cup u_{i} \nonumber \\
	tl(r_{j}) &=& tl(r_{j}) \cup d \nonumber \\
           f(u_{i}, r_{j}, d) &\in &\mathcal{F} \text{ with } \mathcal{P}(q(r_{j}))		
	\end{eqnarray}

	\begin{eqnarray}	
	\hspace{3.5cm}fl(r_{j}) &= &fl(r_{j}) \nonumber \\
	tl(r_{j}) & = &  tl(r_{j}) \nonumber \\
           f(u_{i}, r_{j}, d) &\not \in &\mathcal{F} \text{ with } 1-\mathcal{P}(q(r_{j}))		
	\end{eqnarray}

	\begin{equation}	
	\hspace{4.7cm}q(r_{j})= \max \{q(r_{j}, a(u_{i})) \} \text{ if }{ f(u_{i}, r_{j}, d) \in \mathcal{F}}  
	\end{equation}

	\hspace{3.2cm}end\\

	\hspace{2.4cm}end\\

	\hspace{1.6cm}end\\

	\clearpage
	
	\normalsize
	There are \emph{three} parameters used in the data generation, namely, \emph{simulation length} ($D$),  $\alpha$ and $\beta$. \emph{simulation length} is self descriptive and is used to specify the number of the days to generate matching data.  \par
	We call a \emph{transaction} that a user looks a resource and whether s/he adds it into her/his \emph{favorite} list and denoted by $t$. $\alpha$ is used to calculate the mean ($\mu$) of the normal distribution which is used to generate the number of daily transactions ($t_{max}$). $\beta$ is used to scale the mean ($\mu$) which is calculated by using $\alpha$, to calculate the variance ($\sigma^2$) of the normal distribution and the calculated $\mu$ and $\sigma^2$ are used in the equation ($3.2$). The details of calculation of each as follows: \\

	\begin{equation}
	\mu = \alpha \times U \times R
	\end{equation}
	\begin{equation}
	\sigma^2 =  \beta * \mu 
	\end{equation}
	Here are the step by step procedure explained: 

\begin{itemize}

\item Calculate the mean ($\mu$) of the normal distribution which is used to generate the number of daily transactions by the equation ($3.8$).

\item Calculate the variance ($\sigma^2$) of the normal distribution which is used to generate the number of daily transactions by the equation ($3.9$).

\item Create a pseudo variate generator for the normal distribution with parameters $\mu$ and $\sigma^2$.

\item Set the simulation day to one

\item Repeat as much as \emph{simulation length} ($D$) - equation ($3.1$)

	\begin{itemize}

	\item Generate a number for daily transactions ($t_{max}$) - equation($3.2$)

	\item Repeat as much as $t_{max}$ - equation ($3.3$)

		\begin{itemize}

		\item Randomly choose a user $u_{i}$ - equation($3.4$)

		\item Randomly choose a resource $r_{j}$ - equation($3.4$) 

		\item Check the \emph{favorite list} ($fl(r_{j})$) of the resource $r_{j}$ for the chosen user ($u_{i}$) - equation ($3.5$)

		\item If chosen user $u_{i}$ has already added the chosen resource $r_{j}$ into her/his list, there is no action and continue for new transaction $t$. In other words, the {favorite list} of the resource ($fl(r_{j})$)  already contains the randomly chosen deviant - equation($3.5$) is false

		\item Else equation ($3.5$) is true and user $u_{i}$ hasn't added the chosen resource $r_{j}$ yet, so give a chance to deviant to add the deviation into his list. User $u_{i}$ adds the resource $r_{j}$ into his list with a propability proportional to its quality ($q(r_{j})$) - equation ($3.6$) and ($3.7$)

		\item If chosen user $u_{i}$ adds the chosen resource into his list by equation ($3.6$), update the \emph{quality} of the resource ($r_{j}$) - equation ($3.8$). If influential users add the resource into their list, the \emph{quality} of the resource ($q(r_{j})$) increases and so the probability increases so that other users can add the resource  $r_{j}$ when they meet the resource $r_{j}$

		\end{itemize}

	\end{itemize}

\end{itemize}	

\chapter{Analysis of the Generated Data}

	\section{Algorithm}

	\hspace{0.6cm} We have explained how to generate data, now we will explain the how to analyze the data. Analysis phase doesn't know the internal dynamics of the generated data but since we know true values, we can easily check their correctness and the power of the algorithm.

	\hspace{0.6cm}Firstly, create a \emph{map} because at the end of anaysis this data structure will be filled. This data structure holds a flag for each user-resource pair and this number specifies whether this user is the most influential user for the resource. Therefore, we can define this data strucure a function from users and resources to $\{0,1\}$ since a user is the most influential user or not.

	$$h : \mathcal{U} \times \mathcal{R} \rightarrow \{0, 1\}$$

	$$ \mathcal{H} = \{h(u_{i}, r_{j})| u_{i} \in \mathcal{U}, r_{j} \in \mathcal{R}\}$$
	
	$$hsum(u_{i}) = \sum_{j=1}^R h(u_{i}, r_{j})$$

	$$vsum(u_{i}) = \sum_{j=1}^R \sum_{k=1}^D f(u_{i}, r_{j}, d_{k}) $$

	The bigger $hsum(u_{i})$ is, the more influential user $u_{i}$ may be. After scaling with the size \emph{favorite list} of resources and the number of resources that users has added their list, the distribution of $h(u_{i})$s is correlated with the distribution that is used to generate the users.

	

	Frequency list of a resource is the distribution of the numbers of the users that have added this resource into their list. Therefore, frequency list can be represented as a function from the days of the data to the number of users since at most all users can add the resource in a day.

	$$freq : [1, D] \rightarrow [0, U]$$

	\begin{equation}
	freq(r_{j}, k) = \sum_{i=1}^U f(u_{i}, r_{j}, d_{k}) \text{ where } 1 \le k \le D \nonumber
	\end{equation}

	\begin{equation}
	freqList(r_{i}) = \{freq(r_{i}, k)| 1\le k \le D\} \nonumber
	\end{equation}

	Moreover, we have two more parameters, namely, \emph{derivation window} and \emph{setup window}. The sizes of these windows are effected by the length of the data and daily transactions. Therefore, these window sizes must be chosen while taking consideration the length ($D$) and the average of the daily transactions ($\mu$). Since we can calculate  $\mu$ and $D$ in real data, we can easily agree on the window sizes.

	\begin{eqnarray*}
	dw & \leftarrow & derivation \text{ } window \\
	sw & \leftarrow & setup \text{ } window
	\end{eqnarray*}

	\clearpage 
	
	\text{The algorithm to find the most influential user:}
	\begin{eqnarray*}
	&\hspace{-14.4cm}\text{Foreach } r_{j} \in \mathcal{R} \nonumber\\
	&\hspace{-11.9cm}p(r_{j}) = 0, inc(r_{j}) = 0 \\
	&\hspace{-12.1cm}\text{for } k = 1 \text{ to } D-dw \\
           &\hspace{1cm}p(r_{j}) \text{ }  = k \text{ if } 
	\begin{cases}	
p(r_{j}) \le \sum_{i=k}^{k+dw} freq(r_{j}, i) \\ freq(r_{j}, p(r_{j}))-freq(r_{j}, p(r_{j})-1) \le freq(r_{j}, k) - freq(r_{j}, k-1)\\
	\end{cases}\\
	&\hspace{-10.9cm}\text{for } k = p(r_{j}-sw) \text{ to } p(r_{j})\\
	&\hspace{-1.1cm}\mathcal{H} = \mathcal{H} \cup \{h(fl(r_{j})[m], r_{j})= 1 \} \text{ where } tl(r_{j})[m] = p(r_{j}), 0 \le m \le |fl(r_{j})|\\
	&\hspace{-14.6cm}\text{endfor} \\
	&\hspace{-15.2cm}\text{endforeach} \\
	&\hspace{-11.4cm}maxList = \max\{fl(r_{j})| r_{j} \in \mathcal{R}\} \\
	&\hspace{-14.5cm}\text{for } i = 1 \text{ to } U \\
	&\hspace{-13.1cm}\text{for } j = 1 \text{ to } R \\
	&\hspace{-10.1cm}h(u_{i}, r_{j}) = \frac{h(u_{i}, r_{j}) \times fl(r_{j})}{maxList} \\
	&\hspace{-14.6cm}\text{endfor} \\
	&\hspace{-15.9cm}\text{endfor} \\
	&\hspace{-10.2cm}u_{influential} = max\{\frac{hsum(u_{i})}{vsum(u_{i})}| 1 \le i \le U\}
	\end{eqnarray*}

	\clearpage
	
	\section{Parameter Analysis}

	\begin{itemize}

	\item \textbf{User Distribution Analysis}

\begin{center}
\textup{\textbf{$U=1,000; R=10,000; D=1,000; dw=15; sw=15; \alpha=0.005; \beta=2; 12\text{ }Resource\text{ }Distribution; 100\text{ }Runs$\\}}
\textup{\\}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$n$} & \textbf{$\mu_{real}$} & \textbf{$\mu_{estimated}$} & \textbf{$\Delta$}\\
\hline
0 & 0.9713 & 0.8285 & 0.1428 \\
\hline
2 & 0.9966 & 0.6147 & 0.3819 \\
\hline
4 & 0.9876 & 0.9061 & 0.0814 \\
\hline
6 & 0.9503 & 0.9474 & 0.0029 \\
\hline
8 & 0.8540 & 0.8491 & 0.0049 \\
\hline
10 & 0.7374 & 0.7363 & 0.0010 \\
\hline
\end{tabular}
\end{center}

	\item \textbf{Resource Distribution Analysis}

\begin{center}
\textup{\textbf{$U=1,000; R=10,000; D=1,000; dw=15; sw=15; \alpha=0.005; \beta=2; 12\text{ }User\text{ }Distribution; 500\text{ }Runs$\\}}
\textup{\\}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$n$} & \textbf{$\mu_{real}$} & \textbf{$\mu_{estimated}$} & \textbf{$\Delta$}\\
\hline
0 & 0.6213 & 0.6205 & 0.0008 \\
\hline
2 & 0.6301 & 0.6288 & 0.0013 \\
\hline
4 & 0.6303 & 0.6300 & 0.0003 \\
\hline
6 & 0.6161 & 0.6155 & 0.0006 \\
\hline
8 & 0.6310 & 0.6308 & 0.0002 \\
\hline
10 & 0.6308 & 0.6300 & 0.0008 \\
\hline
\end{tabular}
\end{center}

	\item \textbf{Derivation and Setup Window Analysis}

\begin{center}
\textup{\textbf{$U=1,000; R=10,000; D=1,000; \alpha=0.005; \beta=2; 10\text{ }Resource\text{ }and\text{ }User\text{ }Distribution, 100\text{ }Runs$\\}}
\textup{\\}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$dw-sw$} & \textbf{$\mu_{real}$} & \textbf{$\mu_{estimated}$} & \textbf{$\Delta$}\\
\hline
1 & 0.7274 & 0.6483 & 0.0791 \\
\hline
2 & 0.7326 & 0.7204 & 0.122 \\
\hline
3 & 0.7405 & 0.7324 & 0.0081 \\
\hline
4 & 0.7236 & 0.7210 & 0.0025 \\
\hline
6 & 0.7201 & 0.7172 & 0.0029 \\
\hline
8 & 0.7216 & 0.7154 & 0.0061 \\
\hline
\end{tabular}
\end{center}

	\item \textbf{Simulation Length Analysis}

\begin{center}
\textup{\textbf{$U=1,000; R=10,000; dw=10; sw=10; \alpha=0.005; \beta=2; 8\text{ }Resource\text{ }and\text{ }User\text{ }Distribution; 100\text{ }Runs$\\}}
\textup{\\}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$D$} & \textbf{$\mu_{real}$} & \textbf{$\mu_{estimated}$} & \textbf{$\Delta$}\\
\hline
100 & 0.8665 & 0.8640 & 0.0025 \\
\hline
200 & 0.8588 & 0.8575  & 0.0014 \\
\hline
300 & 0.8529 & 0.8518  & 0.0011 \\
\hline
400 & 0.8395 & 0.8303 & 0.0092 \\
\hline
600 & 0.8465 & 0.8454 & 0.0011 \\
\hline
800 & 0.8623 & 0.8607 & 0.0016 \\
\hline
\end{tabular}
\end{center}


	\item \textbf{Number of Resources and Daily Transactions Analysis}

\begin{center}
\textup{\textbf{$U=1,000; D=500; dw=10; sw=10; \alpha=0.005; \beta=2; 8\text{ }Resource\text{ }and\text{ }User\text{ }Distribution; 100\text{ }Runs$\\}}
\textup{\\}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$R$} & \textbf{$\mu_{real}$} & \textbf{$\mu_{estimated}$} & \textbf{$\Delta$}\\
\hline
300 & 0.8623 & 0.5774 & 0.2848 \\
\hline
625 & 0.8489 & 0.7309 & 0.1181 \\
\hline
1250 & 0.8672 & 0.8287 & 0.0385 \\
\hline
2500 & 0.8470 & 0.8356 & 0.0114\\
\hline
5000 & 0.8547 & 0.8464 & 0.0083\\
\hline
\end{tabular}
\end{center}

	\item \textbf{Daily Transactions Analysis}

\begin{center}
\textup{\textbf{$U = 1,000; R = 2,000; D = 500; dw=10; sw=10; \beta=2; 8 \text{ }Resource \text{ }and \text{ }User\text{ } Distribution; 100\text{ }Runs$\\}}
\textup{\\}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{$\alpha\text{ }(t_{max})$} & \textbf{$\mu_{real}$} & \textbf{$\mu_{estimated}$} & \textbf{$\Delta$}\\
\hline
0.001 (2) & 0.8627 & 0.8053 & 0.0574 \\
\hline
0.002 (4) & 0.8603 & 0.8482 & 0.0122 \\
\hline
0.0025 (5) & 0.8519 & 0.8444 & 0.0075 \\
\hline
0.005 (10) & 0.8555 & 0.8351 & 0.0204 \\
\hline
0.01 (20) & 0.8438 & 0.8016 & 0.0422 \\
\hline
0.02 (40) & 0.8645 & 0.7401 & 0.1244 \\
\hline
0.025 (50) & 0.8569 & 0.6786 & 0.1783 \\
\hline
0.05 (100) & 0.8671 & 0.4177 & 0.4494 \\
\hline
\end{tabular}
\end{center}

	\end{itemize}
\clearpage

	\begin{itemize}

	\item \textbf{Summary:}

		\begin{itemize}

		\item User Distribution is the most important parameter in the simulation. When the mean of the authority values of the most effective users goes down, algorithm gives better results.

		\item When User Distribution is selected carefully, actually sufficiently small, artwork distribution doesn't matter.

		\item The sizes of the derivation and setup windows behave in a bell curve so these window sizes should be chosen by the analysis and should be sufficiently large, not so much because then results worsen.

		\item The longer simulation length  is, the better results are found. Therefore,  simulation length must be long as much as possible.

		\item The number of daily transactions is also important and also follows a bell curve and there is an optimum value to be determined. 

		\end{itemize}

	\end{itemize}

\chapter{Conclusions and Future Work}

	This algorithm sufficiently gives good results when the parameters are chosen with caution. However, there are some difficulties in choosing parameters and distributions that are used to generate the deviants and deviations. \\

	Furthermore, network resolution algorithm works well on the networks whose internal dynamics run as in the network generator algorithm generated networks and we aren't sure DeviantART works as well. \\

	We will specifiy the procedure of the selection of the parameters and then run the algorithm on the DeviantART.  We will follow the users that are found as the most effective user by the algorithm to test the results. 

\chapter{Appendix}

\begin{center}
\large
\textup{\textbf{Distributons of User and Resource Generation\\}}
\normalsize
\textup{These values are just runs of the distribution \emph{10,000} times}
\begin{tabular}{|c|c|c|}
\hline
\textbf{$n$} & \textbf{$\mu$} & \textbf{$\sigma^2$} \\
\hline
0 & 0.3327 & 0.0562\\
\hline
1 & 0.4178 & 0.0789 \\
\hline
2 & 0.3459 & 0.0694 \\
\hline
3 & 0.2791 & 0.0558 \\
\hline
4 & 0.2300 & 0.0425 \\
\hline
5 & 0.1903 & 0.0316 \\
\hline
6 & 0.1647 & 0.0267 \\
\hline
7 & 0.1415 & 0.0198 \\
\hline
8 & 0.1262 & 0.0158 \\
\hline
9 & 0.1097 & 0.0115 \\
\hline
10 & 0.1006 & 0.0102 \\
\hline
11 & 0.0903 & 0.0080 \\
\hline
12 & 0.0825 & 0.0069 \\
\hline
13 & 0.0765 & 0.0059 \\
\hline
14 & 0.0722 & 0.0052 \\
\hline
15 & 0.0663 & 0.0043 \\
\hline
16 & 0.0622 & 0.0039 \\
\hline
17 & 0.0581 & 0.0034 \\
\hline
18 & 0.0560 & 0.0032 \\
\hline
19 & 0.0520 & 0.0027 \\
\hline
20 & 0.0502 & 0.0025 \\
\hline
\end{tabular}
\end{center}

\clearpage

\chapter{References}

\begin{itemize}

\item \textbf{DeviantART} 

http://www.deviantart.com 

\item \textbf{DeviantART in Spotlight: A Network of Arts and Artists }

Almila Akdag Salah, Albert Ali Salah, Bart Buter, Nick Dijkshoorn, Davide Modolo, Quang Nguyen, Sander van Noort, Bart van de Poel VKS/KNAW, Cruiquisweg 31, 1019 AT, Amsterdam, the Netherlands. Informatics Insitute, University of Amsterdam, 1098 XG, Amsterdam, the Netherlands.

\item \textbf{TADA: Toolkit for Analysis of deviantART}

Bart Buter, Nick Dijkshoorn, Davide Modolo, Quang Nguyen, Sander van Noort, Bart van de Poel 

http://code.google.com/p/ppis-deviantart/ 

\item \textbf{Community Structure in social and biological networks}

M. Girvan and E.J Newman, 10.1073/pnas.122653799 PNAS June 11, 2002 vol. 99 no. 12 7821-7826

http://www.pnas.org/content/99/12/7821.full.pdf

\item \textbf{Wikipedia} 

http://en.wikipedia.org/wiki/DeviantArt 

\item \textbf{Wayback Machine}

http://web.archive.org/web/*/http://www.deviantart.com 

\end{itemize}

\end{document}
